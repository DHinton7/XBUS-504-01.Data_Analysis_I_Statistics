{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are first babies more likely to be late?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from \"Teaching statistical inference with resampling,\" Copyright 2018 Allen Downey\n",
    "License: http://creativecommons.org/licenses/by/4.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Jupyter so figures appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure Jupyter to display the assigned value after an assignment\n",
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some people say that first babies are more likely to be late. And some people swear they're early! What's true?\n",
    "\n",
    "The CDC runs the National Survey of Family Growth (NSFG), which \"gathers information on family life, marriage and divorce, pregnancy, infertility, use of contraception, and men’s and women’s health.\" https://www.cdc.gov/nchs/nsfg/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get data and into a Pandas Dataframe:\n",
    "import nsfg\n",
    "\n",
    "df = nsfg.ReadFemPreg()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file contains 13,593 rows, one for each pregnancy reported by a one of the survey respondents, and 244, one for each variable.\n",
    "\n",
    "Here are the first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables we need are `outcome`, which indicates whether the pregnancy ended in a live birth, `birthord`, which indicates birth order, and `prglength`, which is pregnancy length in weeks.\n",
    "\n",
    "From all live births, we can select first babies (`birthord==1`) and others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live = ...\n",
    "firsts = ...\n",
    "others = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(firsts), len(others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can get the list of pregnancy lengths for the two groups and compute their means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = firsts.prglngth\n",
    "group2 = others.prglngth\n",
    "\n",
    "np.mean(group1), np.mean(group2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference in means (in weeks) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the difference in means from weeks to hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff * 7 * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "The size of this \"apparent effect\" is small, and we can't tell whether it is real or the result of random sampling.  After all, we did not survey the entire population; we only surveyed a random sample.\n",
    "\n",
    "There are two ways the sample might deviate from the population:\n",
    "\n",
    "*  Systematic errors: The pregnancies included in the survey might be different from other pregnancies in a way that biases the results.\n",
    "\n",
    "*  Sampling errors: The pregnancies lengths in one groups might be a little higher, or lower, than in the other group because of random variability.\n",
    "\n",
    "We can never rule out the possibility of systematic errors, but usually we can test whether an apparent effect could be explained by random sampling.\n",
    "\n",
    "Here's how:\n",
    "\n",
    "1.  Choose a \"test statistics\" that measures the size of the effect; in this case, the test statistic we started with is the difference in mean pregnancy length.\n",
    "\n",
    "2.  Use the data to make a model of the population under the assumption that there is actually no difference between the groups.  This assumption is called the \"null hypothesis\".\n",
    "\n",
    "3.  Use the model to simulate the data collection process.\n",
    "\n",
    "4.  Use the simulated data to compute the test statistic.\n",
    "\n",
    "4.  Repeat steps 2-4 and collect the results.\n",
    "\n",
    "5.  See how often the simulated test statistic exceeds the observed difference.\n",
    "\n",
    "The following function computes the test statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stat(data):\n",
    "    group1, group2 = data\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = group1, group2\n",
    "actual = test_stat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a model of the population under the assumption that these is actually no difference between the groups.\n",
    "\n",
    "Well, if there's no difference, we can put the two groups together and shuffle them, then divide them at random into two groups with the same sizes.\n",
    "\n",
    "That's what this function does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data):\n",
    "    group1, group2 = data\n",
    "    pool = np.hstack((group1, group2))\n",
    "    np.random.shuffle(pool)\n",
    "    n = len(group1)\n",
    "    return np.split(pool, [n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a list of two arrays, which we can pass to `test_stat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat(run_model(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the result of one simulated experiment.\n",
    "\n",
    "We can run the experiment 1000 times and collect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat_dist = np.array([test_stat(run_model(data)) \n",
    "                           for i in range(1000)])\n",
    "np.mean(test_stat_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the \"sampling distribution of the test statistic under the null hypothesis\".\n",
    "\n",
    "Here's a function to plot the distribution of test stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_stats(test_stats):\n",
    "    plt.xlabel('Difference in mean (weeks)')\n",
    "    plt.title('Distribution of test stat under null hypothesis')\n",
    "    return plot_hist(test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(values, low=None, high=None):\n",
    "    options = dict(alpha=0.5, color='C0')\n",
    "    xs, ys, patches = plt.hist(values,\n",
    "                               normed=True,\n",
    "                               histtype='step', \n",
    "                               linewidth=3,\n",
    "                               **options)\n",
    "    \n",
    "    \n",
    "    plt.ylabel('Density')\n",
    "    plt.tight_layout()\n",
    "    return patches[0]\n",
    "\n",
    "def fill_hist(low, high, patch):\n",
    "    options = dict(alpha=0.5, color='C0')\n",
    "    fill = plt.axvspan(low, high, \n",
    "                       clip_path=patch,\n",
    "                       **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_stats(test_stat_dist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the probability that the test statistic, under the null hypothesis, exceeds the observed differences in the means.\n",
    "\n",
    "This probability is called a \"p-value\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.mean(test_stat_dist >= actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the p-value as the shaded area of the distribution above the observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(text, x, y, length):\n",
    "    arrowprops = dict(width=1, headwidth=6, facecolor='black')\n",
    "    plt.annotate(text,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(x, y+length),\n",
    "                 ha='center',\n",
    "                 arrowprops=arrowprops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = plot_test_stats(test_stat_dist)\n",
    "low = actual\n",
    "high = np.max(test_stat_dist)\n",
    "fill_hist(low, high, patch)\n",
    "annotate('p-value', 1.2*actual, 1.0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different test statistics\n",
    "\n",
    "What we computed in the previous section is the probability that first babies would be *later*, on average, under the null hypothesis. Depending on the context, we might also want to know the probability that first babies would be *earlier* on average.\n",
    "\n",
    "We can include both possibilities by defining a new test statistic, the *absolute* difference in means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stat(data):\n",
    "    group1, group2 = data\n",
    "    return abs(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the observed difference with this test stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test_stat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the actual difference is positive, its absolute value is the same.\n",
    "\n",
    "We can run the simulated experiments with this test statistic, and print the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat_dist = np.array([test_stat(run_model(data)) \n",
    "                       for i in range(1000)])\n",
    "\n",
    "p_value = np.mean(test_stat_dist >= actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the distribution looks like for this test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = plot_test_stats(test_stat_dist)\n",
    "low = actual\n",
    "high = np.max(test_stat_dist)\n",
    "fill_hist(low, high, patch)\n",
    "annotate('p-value', 1.2*actual, 2, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
